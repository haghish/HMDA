% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/hmda.grid.R
\name{hmda.grid}
\alias{hmda.grid}
\title{Tune Hyperparameter Grid for HMDA Framework}
\usage{
hmda.grid(
  algorithm = c("drf", "gbm"),
  grid_id = NULL,
  x,
  y,
  training_frame = h2o.getFrame("hmda.train.hex"),
  validation_frame = NULL,
  hyper_params = list(),
  nfolds = 10,
  seed = NULL,
  fold_column = NULL,
  weights_column = NULL,
  keep_cross_validation_predictions = TRUE,
  stopping_rounds = NULL,
  stopping_metric = "AUTO",
  stopping_tolerance = NULL,
  recovery_dir = NULL,
  sort_by = "logloss",
  ...
)
}
\arguments{
\item{algorithm}{Character. The algorithm to tune. Supported values
are "drf" (Distributed Random Forest) and "gbm"
(Gradient Boosting Machine). Only one algorithm
can be specified. (Case-insensitive)}

\item{grid_id}{Character. Optional identifier for the grid search.
If \code{NULL}, an automatic grid_id is generated
using the algorithm name and the current time.}

\item{x}{Vector. Predictor column names or indices.}

\item{y}{Character. The response column name or index.}

\item{training_frame}{An H2OFrame containing the training data.
Default is \code{h2o.getFrame("hmda.train.hex")}.}

\item{validation_frame}{An H2OFrame for early stopping. Default is \code{NULL}.}

\item{hyper_params}{List. A list of hyperparameter vectors for tuning.
If you do not have a clue about how to specify the
hyperparameters, consider consulting \code{hmda.suggest.param}
and \code{hmda.search.param} functions, which provide
suggestions based on default values or random search.}

\item{nfolds}{Integer. Number of folds for cross-validation.
Default is 10.}

\item{seed}{Integer. A seed for reproducibility.
Default is \code{NULL}.}

\item{fold_column}{Character. Column name for cross-validation fold
assignment. Default is \code{NULL}.}

\item{weights_column}{Character. Column name for observation weights.
Default is \code{NULL}.}

\item{keep_cross_validation_predictions}{Logical. Whether to keep
cross-validation predictions. Default is \code{TRUE}.}

\item{stopping_rounds}{Integer. Number of rounds with no improvement
to trigger early stopping. Default is \code{NULL}.}

\item{stopping_metric}{Character. Metric used for early stopping.
Default is "AUTO".}

\item{stopping_tolerance}{Numeric. Relative tolerance for early stopping.
Default is \code{NULL}.}

\item{recovery_dir}{Character. Directory path to save the grid search
output. If provided, the grid is saved using
\code{h2o.saveGrid()}.}

\item{sort_by}{Character. Metric used to sort the grid. Default is "logloss".}

\item{...}{Additional arguments passed to \code{h2o.grid()}.}
}
\value{
An object of class \code{H2OGrid} containing the grid search
        results.
}
\description{
Generates a hyperparameter grid for a single tree-based
  algorithm (either "drf" or "gbm") by running a grid search.
  The function validates inputs, generates an
  automatic grid ID for the grid (if not provided), and optionally
  saves the grid to a recovery directory. The resulting grid object
  contains all trained models and can be used for further analysis.
  For scientific computing, saving the grid is highly recommended
  to avoid future re-running the training!
}
\details{
The function executes the following steps:
  \enumerate{
    \item \strong{Input Validation:} Ensures only one algorithm is specified
          and verifies that the training frame is an H2OFrame.
    \item \strong{Grid ID Generation:} If no \code{grid_id} is provided, it
          creates one using the algorithm name and the current time.
    \item \strong{Grid Search Execution:} Calls \code{h2o.grid()} with the
          provided hyperparameters and cross-validation settings.
    \item \strong{Grid Saving:} If a recovery directory is specified, the grid
          is saved to disk using \code{h2o.saveGrid()}.
  }
  The output is an H2O grid object that contains all the trained models.
}
\examples{
\dontrun{
  # Example: Create a hyperparameter grid for GBM models.
  predictors <- c("var1", "var2", "var3")
  response <- "target"

  # Define hyperparameter ranges
  hyper_params <- list(
    ntrees = seq(50, 150, by = 25),
    max_depth = c(5, 10, 15),
    learn_rate = c(0.01, 0.05, 0.1),
    sample_rate = c(0.8, 1.0),
    col_sample_rate = c(0.8, 1.0)
  )

  # Run the grid search
  grid <- hmda.grid(
    algorithm = "gbm",
    x = predictors,
    y = response,
    training_frame = h2o.getFrame("hmda.train.hex"),
    hyper_params = hyper_params,
    nfolds = 10,
    stopping_metric = "AUTO"
  )

  # Print the grid search results
  print(grid)
}

}
\author{
E. F. Haghish
}
